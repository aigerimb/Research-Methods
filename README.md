# Research-Methods
This repository contains papers and other resources for the Research Methods class 

## New Papers
## Reinforcement Learning Papers 
1. [Strategic Attentive Writer for Learning Macro-Actions](https://arxiv.org/pdf/1606.04695.pdf)
2. [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952.pdf)
3. [Learning to Paint With Model-based Deep Reinforcement Learning](https://arxiv.org/pdf/1903.04411.pdf)
4. [A Review of Cooperative Multi-Agent Deep Reinforcement Learning](https://arxiv.org/pdf/1908.03963.pdf)
5. [Machine Learning for Combinatorial Optimization: a Methodological Tour dâ€™Horizon](https://arxiv.org/pdf/1811.06128.pdf)
6. [Deep Reinforcement Learning for Autonomous Driving: A Survey](https://arxiv.org/pdf/2002.00444.pdf)
7. [Resource Management with Deep Reinforcement Learning](https://people.csail.mit.edu/alizadeh/papers/deeprm-hotnets16.pdf)

## NLP Papers 

1. [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf)
2. [Neural Approaches to Conversational AI](https://arxiv.org/pdf/1809.08267.pdf)
3. [A Neural Conversational Model](https://arxiv.org/pdf/1506.05869.pdf)
4. [Emotion-Cause Pair Extraction: A New Task To Emotion Analysis In Texts](https://arxiv.org/pdf/1906.01267.pdf)
5. [Analysis Methods in Neural Language Processing: A Survey](https://aclanthology.org/Q19-1004.pdf)


## CV papers 
1. [Animating Pictures with Eulerian Motion Fields](https://openaccess.thecvf.com/content/CVPR2021/papers/Holynski_Animating_Pictures_With_Eulerian_Motion_Fields_CVPR_2021_paper.pdf)
2. [Taming Transformers for High-Resolution Image Synthesis](https://openaccess.thecvf.com/content/CVPR2021/papers/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.pdf)
3. [Computer Vision for Autonomous Vehicles: Problems, Datasets and State of the Art](https://arxiv.org/abs/1704.05519)
4. [Deep learning-enabled medical computer vision](https://www.nature.com/articles/s41746-020-00376-2.pdf)
5. [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640.pdf)
6. [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf)


## Past papers
## Reinforcement Learning Papers 
1. [Playing Atari with Deep Reinforcement Learning, Algorithm: DQN.](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)
2. [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/abs/1602.01783)
3. [Grandmaster level in StarCraft II using multi-agent reinforcement learning](https://www.nature.com/articles/s41586-019-1724-z.epdf?author_access_token=lZH3nqPYtWJXfDA10W0CNNRgN0jAjWel9jnR3ZoTv0PSZcPzJFGNAZhOlk4deBCKzKm70KfinloafEF1bCCXL6IIHHgKaDkaTkBcTEv7aT-wqDoG1VeO9-wO3GEoAMF9bAOt7mJ0RWQnRVMbyfgH9A%3D%3D)
4. [The Ingredients of Real World Robotic Reinforcement Learning](https://openreview.net/pdf?id=rJe2syrtvS)
5. [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)
6. [Deep Reinforcement Learning that matters](https://arxiv.org/pdf/1709.06560.pdf)
7. [Benchmarking Reinforcement Learning Algorithms on Real-World Robots](https://arxiv.org/pdf/1809.07731.pdf)
8. [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581.pdf)
9. [DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills](https://xbpeng.github.io/projects/DeepMimic/2018_TOG_DeepMimic.pdf)
10. [Deep reinforcement learning from human preferences](https://arxiv.org/pdf/1706.03741.pdf)


## NLP Papers 
1. [Attention is all you need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
2. [Sequence to sequence model](https://papers.nips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf)
3. [Neural machine translation by jointly learning to align and translate](https://arxiv.org/abs/1409.0473)
4. [WinoGrande: An Adversarial Winograd Schema Challenge at Scale](https://arxiv.org/pdf/1907.10641.pdf)
5. [Effective approaches to attention-based neural machine translation](https://arxiv.org/abs/1508.04025)
6. [Convolutional sequence to sequence learning](http://proceedings.mlr.press/v70/gehring17a/gehring17a.pdf)
7. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
8. [Reformer: The Efficient Transformer](https://arxiv.org/pdf/2001.04451.pdf)


## CV papers 
1. [Gated Graph Sequence Neural Networks](https://arxiv.org/abs/1511.05493)
2. [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
3. [Graph attention networks](https://arxiv.org/pdf/1710.10903.pdf)
4. [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
5. [Pay attention to MLPs](https://arxiv.org/abs/2105.08050)
6. [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)
7. [DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition](http://proceedings.mlr.press/v32/donahue14.pdf)
8. [Visualizing and Understanding Convolutional Networks](https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)
9. [Face Detection with a 3D Model](https://arxiv.org/pdf/1404.3596.pdf)

